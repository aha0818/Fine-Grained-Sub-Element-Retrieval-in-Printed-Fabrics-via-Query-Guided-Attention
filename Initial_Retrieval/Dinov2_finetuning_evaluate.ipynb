{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from transformers import Dinov2PreTrainedModel, Dinov2Model\n",
    "import csv\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data processing\n",
    "ADE_MEAN = np.array([123.675, 116.280, 103.530]) / 255\n",
    "ADE_STD = np.array([58.395, 57.120, 57.375]) / 255\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(width=224, height=224),\n",
    "    A.Normalize(mean=ADE_MEAN, std=ADE_STD),\n",
    "])\n",
    "\n",
    "# Feature extraction model\n",
    "class Dinov2FeatureExtractor(Dinov2PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.dinov2 = Dinov2Model(config)\n",
    "\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(config.hidden_size, config.hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(config.hidden_size, 256),\n",
    "        )\n",
    "        \n",
    "        for param in self.dinov2.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self._unfreeze_dinov2_layers(2)\n",
    "\n",
    "        for param in self.projection_head.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def _unfreeze_dinov2_layers(self, unfreeze_layers):\n",
    "        try:\n",
    "            total_blocks = len(self.dinov2.encoder.layer)\n",
    "            layers_to_unfreeze = max(0, total_blocks - unfreeze_layers)\n",
    "            \n",
    "            print(f\"Unfreeze the last {unfreeze_layers} Transformer blocks ({layers_to_unfreeze}-{total_blocks-1})\")\n",
    " \n",
    "            for i in range(layers_to_unfreeze, total_blocks):\n",
    "                for param in self.dinov2.encoder.layer[i].parameters():\n",
    "                    param.requires_grad = True\n",
    "                print(f\"Unfreeze block {i}\")\n",
    "\n",
    "            for param in self.dinov2.layernorm.parameters():\n",
    "                param.requires_grad = True\n",
    "            print(\"Unfreeze layernorm layer\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred during unfreezing: {e}\")\n",
    "            print(\"Only train the projection head\")\n",
    "    \n",
    "    def forward(self, pixel_values, output_hidden_states=False, output_attentions=False):\n",
    "        outputs = self.dinov2(\n",
    "            pixel_values,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            output_attentions=output_attentions\n",
    "        )\n",
    "\n",
    "        cls_token = outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
    "        features = self.projection_head(cls_token)  # [batch_size, 256]\n",
    "        \n",
    "        return {\n",
    "            'features': features,\n",
    "            'last_hidden_state': outputs.last_hidden_state,\n",
    "            'hidden_states': outputs.hidden_states,\n",
    "            'attentions': outputs.attentions\n",
    "        }\n",
    "\n",
    "\n",
    "# Model loading\n",
    "def load_model(model_config_path, weights_path, device):\n",
    "    feature_extractor  = Dinov2FeatureExtractor.from_pretrained(model_config_path)\n",
    "    feature_extractor._unfreeze_dinov2_layers(2)\n",
    "    \n",
    "    # Load weights\n",
    "    try:\n",
    "        checkpoint = torch.load(weights_path, map_location=device)\n",
    "        feature_extractor.load_state_dict(checkpoint['feature_extractor_state_dict'])\n",
    "        print(f\"Successfully loaded feature extractor weights from {weights_path}\")\n",
    "        print(f\"Model trained for {checkpoint.get('epoch', 'unknown')} epochs\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model weights: {e}\")\n",
    "        print(\"Using model with default weights\")\n",
    "    \n",
    "    feature_extractor.to(device)\n",
    "    return feature_extractor\n",
    "\n",
    "# Building a feature database from image folder\n",
    "def build_feature_database_from_folder(feature_extractor, image_folder, transform, device):\n",
    "    feature_db = {}\n",
    "    feature_extractor.eval()\n",
    "    \n",
    "    # Get list of image files\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    image_files = [f for f in os.listdir(image_folder) \n",
    "                  if os.path.isfile(os.path.join(image_folder, f)) \n",
    "                  and f.lower().endswith(tuple(image_extensions))]\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images in folder: {image_folder}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(image_folder, img_file)\n",
    "            \n",
    "            try:\n",
    "                # Load image\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                image_np = np.array(image)\n",
    "                \n",
    "                # Transform image\n",
    "                transformed = transform(image=image_np)\n",
    "                image_tensor = torch.tensor(transformed[\"image\"]).permute(2, 0, 1).float().unsqueeze(0).to(device)\n",
    "                \n",
    "                # Feature extraction\n",
    "                features = feature_extractor(image_tensor)[\"features\"].squeeze(0).cpu().numpy()\n",
    "                \n",
    "                # Feature storage\n",
    "                feature_db[img_path] = features\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    return feature_db\n",
    "\n",
    "\n",
    "# Retrieval function\n",
    "def retrieve_images(query_sub_element, feature_extractor, feature_db, top_k=5):\n",
    "    query_np = np.array(query_sub_element)\n",
    "    transformed = val_transform(image=query_np)\n",
    "    query_tensor = torch.tensor(transformed[\"image\"]).permute(2, 0, 1).float().unsqueeze(0).to(device)\n",
    "    \n",
    "    # Feature extraction for query\n",
    "    feature_extractor.eval()\n",
    "    with torch.no_grad():\n",
    "        query_features = feature_extractor(query_tensor)[\"features\"].squeeze(0).cpu().numpy()\n",
    "    \n",
    "    # Similarity computation\n",
    "    similarities = []\n",
    "    for img_path, features in feature_db.items():\n",
    "        sim = np.dot(query_features, features) / (np.linalg.norm(query_features) * np.linalg.norm(features))\n",
    "        similarities.append((img_path, sim))\n",
    "    \n",
    "    # Sort and get top_k results\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_k]\n",
    "\n",
    "# Get retrieval from query file and evaluate\n",
    "def perform_retrieval_from_query_file(model_config_path, weights_path, query_file_path, database_folder, top_k=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    feature_extractor = load_model(model_config_path, weights_path, device)\n",
    "\n",
    "    print(f\"Building feature database from folder: {database_folder}\")\n",
    "    feature_db = build_feature_database_from_folder(feature_extractor, database_folder, val_transform, device)\n",
    "    print(f\"Feature database built with {len(feature_db)} entries\")\n",
    "\n",
    "    try:\n",
    "        with open(query_file_path, 'r') as f:\n",
    "            query_image_paths = [line.strip().split('.png ')[0] + \".png\" for line in f if line.strip()]\n",
    "        \n",
    "        print(f\"Found {len(query_image_paths)} query images in {query_file_path}\")\n",
    "        \n",
    "        # Perform retrieval for each query\n",
    "        all_results = {}\n",
    "        for query_path in query_image_paths:\n",
    "            try:\n",
    "                if not os.path.exists(query_path):\n",
    "                    print(f\"Warning: Query image not found: {query_path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Load query image\n",
    "                query_image = Image.open(query_path).convert('RGB')\n",
    "                # print(f\"\\nPerforming retrieval with query: {query_path}\")\n",
    "                \n",
    "                # Retrieve images\n",
    "                results = retrieve_images(query_image, feature_extractor, feature_db, top_k=top_k)\n",
    "                \n",
    "                # print(f\"Top {top_k} retrieval results:\")\n",
    "                # for i, (path, score) in enumerate(results):\n",
    "                #     print(f\"{i+1}. {path} (Similarity: {score:.4f})\")\n",
    "                \n",
    "                all_results[query_path] = results\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing query {query_path}: {e}\")\n",
    "        \n",
    "        return all_results, feature_db\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading query file: {e}\")\n",
    "        return {}\n",
    "\n",
    "def load_ground_truth(correct_result_file, class_path):\n",
    "    \"\"\"\n",
    "    Load ground truth data from CSV files.\n",
    "    \n",
    "    Parameters:\n",
    "    - correct_result_file: Ground truth including target categories\n",
    "    - class_path: Category information of the query images\n",
    "    \n",
    "    Returns:\n",
    "    - Ground truth dictionary: a dictionary where keys are categories and values are sets of correct results\n",
    "    \"\"\"\n",
    "    # Get query image categories\n",
    "    query_classes = {}\n",
    "    with open(class_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            if len(row) >= 2:\n",
    "                filename = row[0]\n",
    "                class_name = row[1]\n",
    "                query_classes[filename] = class_name\n",
    "    print(f\"Loaded classes for {len(query_classes)} queries\")\n",
    "    \n",
    "    ground_truth = {}\n",
    "    \n",
    "    # Get ground truth results\n",
    "    with open(correct_result_file, 'r') as correct_file:\n",
    "        correct_reader = csv.reader(correct_file)\n",
    "        # Get filenames as key\n",
    "        try:\n",
    "            filenames = next(correct_reader)\n",
    "        except StopIteration:\n",
    "            print(\"Error: Correct results file is empty!\")\n",
    "            return {}\n",
    "        \n",
    "        for row in correct_reader:\n",
    "            for i, value in enumerate(row):\n",
    "                if value.strip():\n",
    "                    if filenames[i] not in ground_truth:\n",
    "                        ground_truth[filenames[i]] = set()\n",
    "                    ground_truth[filenames[i]].add(value.strip())\n",
    "                    # print(class_name, os.path.splitext(value.strip())[0])\n",
    "    # print(ground_truth)\n",
    "    print(f\"Loaded ground truth data for {len(ground_truth)} classes\")\n",
    "    return ground_truth\n",
    "\n",
    "def calculate_ap(retrieved, relevant, top_k=None):\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    \n",
    "    relevant_set = set(relevant)\n",
    "    if top_k is not None:\n",
    "        retrieved = retrieved[:top_k]\n",
    "\n",
    "    precisions = []\n",
    "    num_correct = 0\n",
    "    \n",
    "    for i, item in enumerate(retrieved):\n",
    "        if item in relevant_set:\n",
    "            num_correct += 1\n",
    "            precision = num_correct / (i + 1)\n",
    "            precisions.append(precision)\n",
    "\n",
    "    if not precisions:\n",
    "        return 0.0\n",
    "\n",
    "    return sum(precisions) / min(len(relevant_set), top_k) if top_k else sum(precisions) / len(relevant_set)\n",
    "\n",
    "def evaluate_retrieval_results(retrieval_results, ground_truth, top_k=5):\n",
    "    all_precision = []\n",
    "    all_recall = []\n",
    "    all_f1 = []\n",
    "    all_ap = []\n",
    "\n",
    "    query_to_class = {}\n",
    "    with open('/Dataset/Test_element.csv', 'r') as file: # Testing image names and categories\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            if len(row) >= 2:\n",
    "                query_id = os.path.splitext(row[0])[0]\n",
    "                query_to_class[query_id] = row[1]\n",
    "    \n",
    "    print(f\"Loaded class mappings for {len(query_to_class)} queries\")\n",
    "    \n",
    "    # Evaluate each query and write to CSV\n",
    "    with open('/Output/Test_map.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        for query_path, results in retrieval_results.items():\n",
    "            query_id = os.path.basename(query_path).split(',')[0]\n",
    "            query_class = query_to_class.get(query_id)\n",
    "            \n",
    "            if query_class is None:\n",
    "                print(f\"Warning: No class found for query {query_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Get relevant items from ground truth\n",
    "            relevant_items = ground_truth.get(query_class, set())\n",
    "            \n",
    "            if not relevant_items:\n",
    "                print(f\"Warning: No ground truth items found for class {query_class}\")\n",
    "                continue\n",
    "\n",
    "            retrieved_ids = [os.path.basename(path).split('.')[0] for path, _ in results[:top_k]]\n",
    "\n",
    "            correct_predictions = sum(1 for item in retrieved_ids if item in relevant_items)\n",
    "\n",
    "            precision = correct_predictions / top_k if top_k > 0 else 0\n",
    "            recall = correct_predictions / len(relevant_items) if len(relevant_items) > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            ap = calculate_ap(retrieved_ids, list(relevant_items), top_k=top_k)\n",
    "\n",
    "            all_precision.append(precision)\n",
    "            all_recall.append(recall)\n",
    "            all_f1.append(f1)\n",
    "            all_ap.append(ap)\n",
    "            \n",
    "            # print(f\"Query: {query_id} ({query_class})\")\n",
    "            print(f\"  AP: {ap:.4f}\")\n",
    "            print(f\"  Precision@{top_k}: {precision:.4f}\")\n",
    "            print(f\"  Recall@{top_k}: {recall:.4f}\")\n",
    "            print(f\"  F1-score@{top_k}: {f1:.4f}\")\n",
    "\n",
    "            writer.writerow([query_id, query_class, ap, precision, recall, f1])\n",
    "\n",
    "    avg_precision = np.mean(all_precision) if all_precision else 0\n",
    "    avg_recall = np.mean(all_recall) if all_recall else 0\n",
    "    avg_f1 = np.mean(all_f1) if all_f1 else 0\n",
    "    map_score = np.mean(all_ap) if all_ap else 0\n",
    "    \n",
    "    print(f\"\\nAverage Metrics (Top-{top_k}):\")\n",
    "    print(f\"  MAP: {map_score:.4f}\")\n",
    "    print(f\"  Precision: {avg_precision:.4f}\")\n",
    "    print(f\"  Recall: {avg_recall:.4f}\")\n",
    "    print(f\"  F1-score: {avg_f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'map': map_score,\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1': avg_f1\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_config_path = \"/Weight_Path/dinov2-pytorch-base-v1\" # Pre-trained model path\n",
    "    weights_path = \"/Weight_Path/dinov2_finetuning2_epoch_100.pth\" # Fine-tuned weights path\n",
    "\n",
    "    database_folder = \"/Dataset/SimulatedPrintedFabrics-17k/test/img/images\" # Testing database folder\n",
    "    query_image_path = \"/Dataset/test.txt\" # Query image list file\n",
    "\n",
    "    correct_result_file = \"/Dataset/TestAll_index.csv\"\n",
    "    class_path = \"/Dataset/Test_element.csv\"\n",
    "\n",
    "    retrieval_results = perform_retrieval_from_query_file(\n",
    "        model_config_path, weights_path, query_image_path, database_folder, top_k=1)\n",
    "\n",
    "    ground_truth = load_ground_truth(correct_result_file, class_path)\n",
    "\n",
    "    if retrieval_results and ground_truth:\n",
    "        evaluate_retrieval_results(retrieval_results[0], ground_truth, top_k=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myj_jupyterlab",
   "language": "python",
   "name": "myj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
